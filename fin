package ru.cib.pkaptdul.lettercred

import org.apache.spark.sql.{SparkSession, DataFrame, Column}
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._

/**
 * Letter of Credit datamart
 */
object LetterCredJob {

  def main(args: Array[String]): Unit = {

    val spark = SparkSession.builder()
      .appName("LetterCredDatamart")
      .enableHiveSupport()
      .getOrCreate()

    import spark.implicits._

    val startDate = lit(args(0)).cast("date")
    val endDate   = lit(args(1)).cast("date")

    val schemaTradefin = "tradefin"
    val schemaRdm      = "rdm"
    val schemaGmrates  = "gmrates"

    // =========================================================
    // RAW VIEW
    // =========================================================
    val rawDf = LetterCredRawView.gen(
      spark,
      schemaTradefin,
      startDate,
      endDate
    )

    rawDf.write.mode("overwrite")
      .saveAsTable("custom_cib_pkaptdul_stg.letter_cred_raw")

    // =========================================================
    // AGG VIEW
    // =========================================================
    val aggDf = LetterCredAggView.gen(
      spark,
      rawDf,
      schemaRdm,
      schemaGmrates
    )

    aggDf.write.mode("overwrite")
      .saveAsTable("custom_cib_pkaptdul.letter_cred_agg")
  }
}

// ======================================================================
// RAW
// ======================================================================
object LetterCredRawView {

  def gen(
    spark: SparkSession,
    schemaTradefin: String,
    startDate: Column,
    endDate: Column
  ): DataFrame = {

    import spark.implicits._

    val agr     = spark.table(s"$schemaTradefin.agr")
    val agrFin  = spark.table(s"$schemaTradefin.agr_fin").filter($"end_dt" === "9999-12-31")
    val agrProc = spark.table(s"$schemaTradefin.agr_proc")
    val lct     = spark.table(s"$schemaTradefin.letter_cred_type")

    val planPayment = spark.table(s"$schemaTradefin.letter_cred_org_plan_payment")
      .filter(split($"sid","\\|")(0).isin("VOZMPA4410","VOZMPA"))
      .filter(coalesce($"letter_cred_org_plan_payment_amt", lit(0)) > 0)
      .filter($"letter_cred_org_plan_payment_dt" >= startDate)
      .select($"plan_payment_agr_sk".alias("agr_sk"))
      .distinct()

    val agrBase = agr
      .join(lct, $"agr.letter_cred_type_sk" === $"lct.letter_cred_type_sk")
      .join(agrFin, Seq("agr_sk"))
      .join(agrProc, Seq("agr_sk"))
      .filter(
        ($"lct.sid".isin("1","2","10") || $"agr.type_code".isin("ind","ind_draft")) &&
        $"open_dt" < endDate
      )

    val agrList = agrBase
      .join(planPayment, Seq("agr_sk"), "left")
      .filter(
        $"close_dt".isNull ||
        $"plan_payment_agr_sk".isNotNull ||
        ($"close_dt" > startDate && $"close_dt" < endDate)
      )
      .select(
        $"agr_sk",
        $"lct.sid".alias("agr_sid"),
        $"num".alias("agr_num"),
        $"docum_tran_amt",
        $"docum_tran_crncy_sk",
        $"letter_cred_coverage_flag",
        $"letter_cred_source_coverage_type_sk",
        $"open_dt",
        $"close_dt",
        $"letter_cred_org_buyer_subj_sk",
        $"docum_tran_seller_subj_sk"
      )
      .distinct()

    val optn  = spark.table(s"$schemaTradefin.optn")
    val toptn = spark.table(s"$schemaTradefin.toptn")

    val operations = optn
      .join(toptn, Seq("toptn_sk"))
      .filter($"optn_dttm".between(startDate, endDate))
      .select(
        $"agr_sk",
        $"optn_dttm",
        $"type_code",
        $"sum_opt_amt",
        $"crncy_sk".alias("optn_crncy_sk"),
        $"group_code"
      )

    agrList.join(operations, Seq("agr_sk"), "left")
  }
}

// ======================================================================
// AGG
// ======================================================================
object LetterCredAggView {

  def gen(
    spark: SparkSession,
    rawDf: DataFrame,
    schemaRdm: String,
    schemaGmrates: String
  ): DataFrame = {

    import spark.implicits._

    val crncy = spark.table(s"$schemaRdm.crncy")
      .select($"crncy_sk", $"digital_code")

    val rate   = spark.table(s"$schemaGmrates.cbr_exchange_rate")
    val rateDt = spark.table(s"$schemaGmrates.cbr_exchange_rate_dt")
      .filter($"point_dt" === current_date())

    val opRate = rate
      .join(rateDt, Seq("cbr_exchange_rate_sk"))
      .withColumnRenamed("rub_rate_amt","op_rub_rate")
      .withColumnRenamed("qty_rub_cnt","op_qty")

    val dealRate = opRate
      .withColumnRenamed("crncy_sk","deal_crncy_sk")
      .withColumnRenamed("op_rub_rate","deal_rub_rate")
      .withColumnRenamed("op_qty","deal_qty")

    val rawFx = rawDf
      .join(crncy.withColumnRenamed("crncy_sk","optn_crncy_sk"), Seq("optn_crncy_sk"), "left")
      .join(crncy.withColumnRenamed("crncy_sk","deal_crncy_sk"), $"docum_tran_crncy_sk" === $"deal_crncy_sk", "left")
      .join(opRate, Seq("optn_crncy_sk"), "left")
      .join(dealRate, $"docum_tran_crncy_sk" === $"deal_crncy_sk", "left")
      .withColumn("op_qty",   when($"op_qty".isNull || $"op_qty" === 0, lit(1)).otherwise($"op_qty"))
      .withColumn("deal_qty", when($"deal_qty".isNull || $"deal_qty" === 0, lit(1)).otherwise($"deal_qty"))
      .withColumnRenamed("digital_code","op_digital_code")
      .withColumnRenamed("deal_digital_code","deal_digital_code")

    def fxToDeal(amount: Column): Column =
      when($"op_digital_code" === $"deal_digital_code", amount)
        .when($"op_digital_code" =!= "643" && $"deal_digital_code" === "643",
          (amount * $"op_rub_rate") / $"op_qty"
        )
        .when($"op_digital_code" === "643" && $"deal_digital_code" =!= "643",
          (amount * $"deal_qty") / $"deal_rub_rate"
        )
        .otherwise(
          (amount * $"op_rub_rate" * $"deal_qty") / ($"op_qty" * $"deal_rub_rate")
        )

    def aggOp(groups: Seq[String], alias: String): DataFrame =
      rawFx
        .filter($"group_code".isin(groups:_*) && $"type_code" === "Operation")
        .withColumn(alias, fxToDeal($"sum_opt_amt"))
        .groupBy($"agr_sk", $"agr_num")
        .agg(round(sum(col(alias)),2).alias(alias))

    val payDF   = aggOp(Seq("PrePay","Prepay","Pay","Expire"),      "nSumPay")
    val payEcDF = aggOp(Seq("PrePay","Prepay","Pay","ReturnCover"), "nSumPayEC")
    val coverDF = aggOp(Seq("Cover"),                               "pa_amount_rep_dt")

    val migrated = rawFx
      .filter($"group_code" === "Migration")
      .select($"agr_sk")
      .distinct()
      .withColumn("is_migrated", lit(true))

    rawFx
      .select($"agr_sk", $"agr_num", $"docum_tran_amt", $"letter_cred_coverage_flag")
      .distinct()
      .join(payDF,   Seq("agr_sk","agr_num"), "left")
      .join(payEcDF, Seq("agr_sk","agr_num"), "left")
      .join(coverDF, Seq("agr_sk","agr_num"), "left")
      .join(migrated, Seq("agr_sk"), "left")
      .na.fill(0)
      .withColumn(
        "balance_cur_end",
        round(
          when($"letter_cred_coverage_flag" === false,
            $"docum_tran_amt" - $"nSumPay"
          ).otherwise(
            $"pa_amount_rep_dt" - $"nSumPayEC"
          ), 2
        )
      )
  }
}
