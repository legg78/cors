скрипт переписал import org.apache.spark.sql.{SparkSession, DataFrame}
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._

val spark = SparkSession.builder()
  .appName("LettersCreditRawDataOptimized")
  .enableHiveSupport()
  .getOrCreate()

// === Схемы исходных данных ===
val schemaTradefin = "usl_tradefin_ndl_uvdo_snp"
val schemaSubj    = "usl_subj_org_idl_snp"
val schemaRdm     = "usl_rdm_idl_spark_snp"
val schemaGmrates = "usl_gmrates_idl_snp"

// === Параметры периода отчета ===
val dateStart = "2020-01-01"
val dateEnd   = "2025-11-01"

// === Субъекты ===
val subjTradefin = spark.table(s"$schemaTradefin.subj_h")
val subjOrg      = spark.table(s"$schemaSubj.subj_h")

val subjList = subjTradefin.select("subj_dp_code", "subj_sk", "inn_num")
  .union(subjOrg.select("subj_dp_code", "subj_sk", "inn_num"))
  .persist()  // небольшая таблица, можно кэшировать

// === Сделки / аккредитивы ===
val agrProc = spark.table(s"$schemaTradefin.agr_proc")
val agr     = spark.table(s"$schemaTradefin.agr")
val lct     = spark.table(s"$schemaTradefin.letter_cred_type")
val agrFin  = spark.table(s"$schemaTradefin.agr_fin")

val agrListPre = agrProc
  .join(agr, Seq("agr_sk"))
  .join(lct, Seq("letter_cred_type_sk"))
  .filter($"lct.sid".isin("1","2","10") || $"agr.type_code".isin("ind","ind_draft"))
  .select($"agr_sk").distinct()

// === Плановые платежи ===
val planPayment = spark.table(s"$schemaTradefin.letter_cred_org_plan_payment")
  .join(agrListPre, $"plan_payment_agr_sk" === $"agr_sk")
  .filter($"letter_cred_org_plan_payment_amt".isNotNull && $"letter_cred_org_plan_payment_amt" > 0)
  .filter($"letter_cred_org_plan_payment_dt" >= dateStart)
  .select($"plan_payment_agr_sk".alias("agr_sk"))
  .distinct()

// === Финальный список аккредитивов ===
val agrListFin = agrListPre
  .join(agr, Seq("agr_sk"))
  .join(agrFin.filter($"end_dt" === "9999-12-31"), Seq("agr_sk"))
  .join(planPayment, Seq("agr_sk"), "left")
  .filter($"open_dt" < dateEnd && ($"close_dt".isNull || $"plan_sk".isNotNull || ($"close_dt" > dateStart && $"close_dt" < dateEnd)))
  .select($"agr_sk", $"sid", $"num", $"docum_tran_amt", $"docum_tran_crncy_sk", $"letter_cred_coverage_flag",
          $"letter_cred_source_coverage_type_sk", $"open_dt", $"close_dt")
  .persist() // часто используемый DF, кэширование оправдано

// === Операции по аккредитивам ===
val operations = spark.table(s"$schemaTradefin.optn")
  .join(spark.table(s"$schemaTradefin.toptn"), Seq("toptn_sk"), "left")
  .join(agrListFin.select("agr_sk"), Seq("agr_sk"))
  .filter($"optn_dttm" >= dateStart && $"optn_dttm" <= dateEnd)
  .select($"agr_sk", $"optn_dttm", $"type_code", $"sum_opt_amt", $"crncy_dp_code", $"crncy_sk", $"group_code")
  .persist()  // кэшируем, так как будет много join'ов

// === Курсы валют ===
val crncy      = spark.table(s"$schemaRdm.crncy")
val cbrRate    = spark.table(s"$schemaGmrates.cbr_exchange_rate")
val cbrRateDt  = spark.table(s"$schemaGmrates.cbr_exchange_rate_dt").filter($"point_dt" === current_date)

// === Объединение всех сырых данных ===
val rawData = agrListFin
  .join(operations, Seq("agr_sk"), "left")
  .join(crncy, Seq("crncy_sk"), "left")
  .join(cbrRate, Seq("crncy_sk"), "left")
  .join(cbrRateDt, Seq("cbr_exchange_rate_sk"), "left")
  .join(subjList.select($"subj_sk".alias("buyer_sk"), $"inn_num".alias("buyer_inn")),
        $"buyer_sk" === $"agr_proc.letter_cred_org_buyer_subj_sk", "left")
  .join(subjList.select($"subj_sk".alias("seller_sk"), $"inn_num".alias("seller_inn")),
        $"seller_sk" === $"agr_proc.docum_tran_seller_subj_sk", "left")
  .select(
    $"agr_sk",
    $"num",
    $"docum_tran_amt",
    $"docum_tran_crncy_sk",
    $"open_dt",
    $"close_dt",
    $"letter_cred_coverage_flag",
    $"letter_cred_source_coverage_type_sk",
    $"optn_dttm",
    $"type_code",
    $"sum_opt_amt",
    $"group_code",
    $"crncy_dp_code",
    $"iso_code".alias("currency_iso"),
    $"rub_rate_amt",
    $"qty_rub_cnt",
    $"buyer_inn",
    $"seller_inn"
  )

// === Сохраняем как Hive-таблицу для последующего расчета и выгрузки в Postgres ===
rawData.write.mode("overwrite").saveAsTable("dw_letters_credit_raw_optimized")

// === Освобождение кэша после сохранения ===
subjList.unpersist()
agrListFin.unpersist()
operations.unpersist()
