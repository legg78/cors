import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
import java.time.LocalDate

object CreditReportVitrine {

  def main(args: Array[String]): Unit = {

    val spark = SparkSession.builder()
      .appName("CreditReportVitrine")
      .getOrCreate()

    import spark.implicits._

    // ======================
    // –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—Ç—á—ë—Ç–∞
    // ======================
    val reportDate = LocalDate.now.minusDays(1)

    // ======================
    // 1. –î–æ–≥–æ–≤–æ—Ä
    // ======================
    val agrDF =
      spark.table("prx_usl_tradefin_ndl_uvdo_xs_snp_usl_tradefin_ndl_uvdo_xs_snp.agr")
        .filter(col("letter_cred_type_sk").isNotNull)
        .select(
          col("agr_sk"),
          col("sid").as("agr_sid"),
          col("num").as("agr_num"),
          col("open_dt"),
          col("close_dt"),
          col("letter_cred_coverage_flag").as("coverage_flag"),
          col("letter_cred_source_coverage_type_sk").as("coverage_type_sk")
        )

    // ======================
    // 2. –§–∏–Ω–∞–Ω—Å—ã –¥–æ–≥–æ–≤–æ—Ä–∞
    // ======================
    val agrFinDF =
      spark.table("prx_usl_tradefin_ndl_uvdo_xs_snp_usl_tradefin_ndl_uvdo_xs_snp.agr_fin")
        .filter(col("end_dt") === "9999-12-31")
        .select(
          col("agr_sk"),
          col("docum_tran_amt"),
          col("docum_tran_crncy_sk").as("crncy_sk")
        )

    // ======================
    // 3. –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç—ã
    // ======================
    val agrProcDF =
      spark.table("prx_usl_tradefin_ndl_uvdo_xs_snp_usl_tradefin_ndl_uvdo_xs_snp.agr_proc")
        .select(
          col("agr_sk"),
          col("letter_cred_org_buyer_subj_sk").as("buyer_subj_sk"),
          col("docum_tran_seller_subj_sk").as("seller_subj_sk")
        )

    // ======================
    // 4. –ö–ª–∏–µ–Ω—Ç—ã (–ò–ù–ù) ‚Äî –æ–±–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    // ======================
    val clientsDF =
      spark.table("prx_usl_subj_org_idl_snp.subj_h")
        .filter(col("end_dt") === "9999-12-31")
        .select(col("subj_sk"), col("inn_num"))
        .union(
          spark.table("prx_usl_tradefin_ndl_uvdo_xs_snp_usl_tradefin_ndl_uvdo_xs_snp.subj_h")
            .filter(col("end_dt") === "9999-12-31")
            .select(col("subj_sk"), col("inn_num"))
        )
        .distinct()

    // ======================
    // 5. –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∏—Ç—Ä–∏–Ω–∞
    // ======================
    val finalDF =
      agrDF
        .join(agrFinDF, Seq("agr_sk"), "left")
        .join(agrProcDF, Seq("agr_sk"), "left")

        // –ò–ù–ù –ø–æ–∫—É–ø–∞—Ç–µ–ª—è
        .join(
          clientsDF.withColumnRenamed("subj_sk", "buyer_subj_sk"),
          Seq("buyer_subj_sk"),
          "left"
        )
        .withColumnRenamed("inn_num", "buyer_inn")

        // –ò–ù–ù –ø—Ä–æ–¥–∞–≤—Ü–∞
        .join(
          clientsDF.withColumnRenamed("subj_sk", "seller_subj_sk"),
          Seq("seller_subj_sk"),
          "left"
        )
        .withColumnRenamed("inn_num", "seller_inn")

        // FX —Å–ª–æ–π (–®–ê–ì 3)
        .join(agrWithBalanceRubDF, Seq("agr_sk"), "left")

        // –û–ø–µ—Ä–∞—Ü–∏–∏ (–®–ê–ì 2)
        .join(operationsAggDF, Seq("agr_sk"), "left")

        .select(
          lit(reportDate).as("report_date"),
          col("agr_sk"),
          col("agr_sid"),
          col("agr_num"),
          col("open_dt"),
          col("close_dt"),
          col("coverage_flag"),
          col("coverage_type_sk"),
          col("docum_tran_amt"),
          col("balance_rub"),
          col("buyer_inn"),
          col("seller_inn"),
          col("sum_percent_amt"),
          col("sum_defer_fee_amt"),
          col("sum_bank_pay_amt"),
          col("sum_bank_return_amt"),
          col("sum_pay_amt"),
          col("sum_cover_amt"),
          col("is_migration_flag").cast("boolean")
        )

    // ======================
    // –ó–∞–ø–∏—Å—å –≤–∏—Ç—Ä–∏–Ω—ã
    // ======================
    finalDF.write
      .mode("overwrite")
      .format("parquet")
      .save("/data/credit_report_vitrine")

    spark.stop()
  }
}

-------------------------

1Ô∏è‚É£ subj_h (clientsDF)
–ß—Ç–æ –µ—Å—Ç—å

2 —Ç–∞–±–ª–∏—Ü—ã

–æ–±–µ partitioned by p1month

–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è:

buyer INN

seller INN

‚ö†Ô∏è –†–µ–∞–ª—å–Ω—ã–π —Ä–∏—Å–∫

union + distinct

—á—Ç–µ–Ω–∏–µ –≤—Å–µ—Ö –ø–∞—Ä—Ç–∏—Ü–∏–π, –µ—Å–ª–∏ –Ω–µ—Ç —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ p1month

join –ø–æ subj_sk ‚Üí shuffle

‚úÖ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —Å–¥–µ–ª–∞—Ç—å
1. –§–∏–ª—å—Ç—Ä end_dt = '9999-12-31' –î–û union

(—á—Ç–æ–±—ã —É–º–µ–Ω—å—à–∏—Ç—å –¥–∞–Ω–Ω—ã–µ)

2. Persist
val clientsDF =
  subj1
    .filter($"end_dt" === "9999-12-31")
    .select("subj_sk", "subj_dp_code", "inn_num")
    .union(
      subj2
        .filter($"end_dt" === "9999-12-31")
        .select("subj_sk", "subj_dp_code", "inn_num")
    )
    .distinct()
    .persist(StorageLevel.MEMORY_AND_DISK)


üìå –≠—Ç–æ —Å–∞–º–æ–µ –æ–ø—Ä–∞–≤–¥–∞–Ω–Ω–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–æ –≤—Å—ë–º –ø–∞–π–ø–ª–∞–π–Ω–µ.

2Ô∏è‚É£ agr (4.1 –º–ª–Ω —Å—Ç—Ä–æ–∫, –±–µ–∑ –ø–∞—Ä—Ç–∏—Ü–∏–π)
–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç

full scan –∫–∞–∂–¥—ã–π –∑–∞–ø—É—Å–∫

–æ–Ω –±—É–¥–µ—Ç driving table –¥–ª—è –≤—Å–µ—Ö join‚Äô–æ–≤

‚ùå –ß—Ç–æ –ù–ï –¥–µ–ª–∞—Ç—å

‚ùå cache agr

‚ùå temp table

‚úÖ –ß—Ç–æ –ú–û–ñ–ù–û (–∏ –Ω—É–∂–Ω–æ)
–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ä–∞–Ω–æ —Å—É–∑–∏—Ç—å agr
val agrBaseDF =
  agrDF
    .filter($"type_code".isin("ind", "ind_draft"))
    .filter($"open_dt" < dateEnd)


–õ—é–±–æ–µ —É—Å–ª–æ–≤–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –ª–æ–≥–∏—á–µ—Å–∫–∏ –¥–æ–ø—É—Å—Ç–∏–º–æ ‚Äî –î–û join‚Äô–æ–≤.

3Ô∏è‚É£ agr_proc + —Ñ–∏–ª—å—Ç—Ä –ø–æ buyer / seller
–•–æ—Ä–æ—à–∞—è –Ω–æ–≤–æ—Å—Ç—å

partitioned (p1month)

join –ø–æ agr_sk

‚ö†Ô∏è –í–∞–∂–Ω–æ

INN-—Ñ–∏–ª—å—Ç—Ä –ù–ï —á–µ—Ä–µ–∑ subj_h ‚Üí agr, –∞:

agr_proc
  .filter(
    $"letter_cred_org_buyer_subj_sk".isin(buyerSubjSk) ||
    $"docum_tran_seller_subj_sk".isin(sellerSubjSk)
  )


–¢–æ –µ—Å—Ç—å:

—Å–Ω–∞—á–∞–ª–∞ clientsDF

–ø–æ—Ç–æ–º semi-join –≤ agr_proc

–∏ —Ç–æ–ª—å–∫–æ –ø–æ—Ç–æ–º join —Å agr

–≠—Ç–æ —Å–∏–ª—å–Ω–æ —É–º–µ–Ω—å—à–∞–µ—Ç agr.

4Ô∏è‚É£ letter_cred_org_plan_payment (3960 —Å—Ç—Ä–æ–∫)
üíé –ò–¥–µ–∞–ª—å–Ω—ã–π dimension

3960 —Å—Ç—Ä–æ–∫

–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ existence-check

join –ø–æ agr_sk

‚úÖ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û
import org.apache.spark.sql.functions.broadcast

val planPaymentDF = broadcast(
  spark.table("letter_cred_org_plan_payment")
    .filter($"letter_cred_org_plan_payment_amt" > 0)
    .filter($"letter_cred_org_plan_payment_dt" >= dateStart)
)


üìà –≠—Ç–æ —É–±–µ—Ä—ë—Ç shuffle –ø–æ–ª–Ω–æ—Å—Ç—å—é.

5Ô∏è‚É£ letter_cred_type (14 —Å—Ç—Ä–æ–∫)
–î–∞–∂–µ –æ–±—Å—É–∂–¥–∞—Ç—å –Ω–µ—á–µ–≥–æ üòÑ
val lctDF = broadcast(
  spark.table("letter_cred_type")
)

6Ô∏è‚É£ agr_fin
–û–ö

partitioned

SCD

join –ø–æ agr_sk

–í–ê–ñ–ù–û

–§–∏–ª—å—Ç—Ä SCD:

.filter(current_date.between($"start_dt", $"end_dt"))


–¥–æ join, –∏–Ω–∞—á–µ –±—É–¥–µ—Ç explode —Å—Ç—Ä–æ–∫.

7Ô∏è‚É£ –ù—É–∂–Ω–æ –ª–∏ –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å agrBaseDF?
–û—Ç–≤–µ—Ç: ‚ùì –∑–∞–≤–∏—Å–∏—Ç
–°—Ü–µ–Ω–∞—Ä–∏–π	–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è
1 —Ñ–∏–Ω–∞–ª—å–Ω—ã–π join	‚ùå –Ω–µ –∫—ç—à–∏—Ç—å
agr –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 2+ —Ä–∞–∑	‚úÖ persist
–∞–≥—Ä–µ–≥–∞—Ü–∏–∏ + –ø–æ–≤—Ç–æ—Ä–Ω—ã–µ join	‚úÖ

–ï—Å–ª–∏ —Ç—ã –¥–µ–ª–∞–µ—à—å –û–î–ù–£ –≤–∏—Ç—Ä–∏–Ω—É ‚Üí write ‚Äî –Ω–µ –Ω–∞–¥–æ.

üß† –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è (–∫–æ—Ä–æ—Ç–∫–æ)
‚úÖ –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ

clientsDF.persist(MEMORY_AND_DISK)

broadcast(letter_cred_type)

broadcast(plan_payment)

—Ä–∞–Ω–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä—ã SCD (end_dt, start_dt)

‚ö†Ô∏è –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ

persist agrBaseDF, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è >1 —Ä–∞–∑–∞

‚ùå –ù–µ –¥–µ–ª–∞—Ç—å

–∫—ç—à–∏—Ç—å agr

temp tables

broadcast –±–æ–ª—å—à–∏—Ö fact‚Äô–æ–≤

üèÅ –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ —Å —É—á—ë—Ç–æ–º DDL
–ö—Ä–∏—Ç–µ—Ä–∏–π	–û—Ü–µ–Ω–∫–∞
–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞	9 / 10
Join-—Å—Ç—Ä–∞—Ç–µ–≥–∏—è	9 / 10
–†–∞–±–æ—Ç–∞ —Å SCD	8.5 / 10
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫—ç—à–∞	9 / 10 (–ø–æ—Å–ª–µ –ø—Ä–∞–≤–æ–∫)
–û–±—â–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å	9.3 / 10
